import os
import asyncio
import logging
import subprocess
import random
from groq import Groq
from pathlib import Path
from shutil import copy2

from aiogram import Bot, Dispatcher, F
from aiogram.types import Message, FSInputFile
from aiogram.filters import Command

from PIL import Image, ImageDraw, ImageFont, ImageOps, ImageEnhance
from pilmoji import Pilmoji

# API –∫–ª—é—á Groq (–∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è)
GROQ_API_KEY = os.getenv("GROQ_API_KEY", "")
groq_client = Groq(api_key=GROQ_API_KEY) if GROQ_API_KEY else None

# –¢–æ–∫–µ–Ω –±–æ—Ç–∞ (–∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è)
TOKEN = os.getenv("BOT_TOKEN", "")

BASE_DIR = Path(__file__).resolve().parent
log_file = BASE_DIR / "bot.log"

# –ó–∞–≥–ª—É—à–∫–∞ –¥–ª—è –∞–≤–∞—Ç–∞—Ä–∫–∏
FALLBACK_AVATAR = str(BASE_DIR / "123.png")

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —à—Ä–∏—Ñ—Ç–æ–≤ (–ø–æ—Ä—è–¥–æ–∫ –ø–æ–∏—Å–∫–∞)
FONT_PATHS = [
    str(BASE_DIR / "times.ttf"),
    "/usr/share/fonts/truetype/msttcorefonts/Times_New_Roman.ttf",
    "/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf",
    "/usr/share/fonts/truetype/liberation/LiberationSerif-Bold.ttf",
]

# –®—Ä–∏—Ñ—Ç—ã —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π Unicode
UNICODE_FONT_PATHS = [
    "/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf",
    "/usr/share/fonts/truetype/noto/NotoSans-Regular.ttf",
    "/usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf",
]

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[
        logging.FileHandler(log_file, encoding="utf-8"),
        logging.StreamHandler(),
    ],
)

bot = Bot(token=TOKEN)
dp = Dispatcher()

OVERLOAD_IMAGE_2 = "/root/bots/2.jpg"
OVERLOAD_IMAGE_3 = "/root/bots/3.png"
MAX_CONCURRENT_PROCESSES = 2

def check_server_load():
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–≥—Ä—É–∑–∫—É –Ω–∞ —Å–µ—Ä–≤–µ—Ä"""
    try:
        result = subprocess.run(['pgrep', '-c', 'ffmpeg'], capture_output=True, text=True)
        count = int(result.stdout.strip()) if result.returncode == 0 else 0
        can_process = count < MAX_CONCURRENT_PROCESSES
        
        logging.info(f"Load check: {count} processes, limit {MAX_CONCURRENT_PROCESSES}, can_process={can_process}")
        
        return can_process, count
    except Exception as e:
        logging.warning(f"Failed to check load: {e}")
        return True, 0  # –ï—Å–ª–∏ –æ—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ - —Ä–∞–∑—Ä–µ—à–∞–µ–º

async def send_overload_message(message: Message, process_count: int):
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ –æ –ø–µ—Ä–µ–≥—Ä—É–∑–∫–µ"""
    try:
        logging.info(f"Sending overload message for {process_count} processes")
        
        if process_count <= MAX_CONCURRENT_PROCESSES + 1:
            image_path = OVERLOAD_IMAGE_2
            caption = f"‚ö†Ô∏è –°–µ—Ä–≤–µ—Ä –∑–∞–≥—Ä—É–∂–µ–Ω ({process_count} –ø—Ä–æ—Ü–µ—Å—Å–æ–≤)\n–ü–æ–ø—Ä–æ–±—É–π —á–µ—Ä–µ–∑ —Å–µ–∫—É–Ω–¥—É"
            logging.info(f"Using light overload image: {image_path}")
        else:
            image_path = OVERLOAD_IMAGE_3
            caption = f"‚ö†Ô∏è –°–µ—Ä–≤–µ—Ä –ø–µ—Ä–µ–≥—Ä—É–∂–µ–Ω ({process_count} –ø—Ä–æ—Ü–µ—Å—Å–æ–≤)\n–ü–æ–¥–æ–∂–¥–∏ –Ω–µ–º–Ω–æ–≥–æ"
            logging.info(f"Using heavy overload image: {image_path}")
        
        logging.info(f"Image exists: {os.path.exists(image_path)}")
        
        if os.path.exists(image_path):
            await message.answer_photo(
                FSInputFile(image_path),
                caption=caption
            )
            logging.info("Overload image sent successfully")
        else:
            logging.error(f"Overload image not found: {image_path}")
            await message.answer(f"‚ö†Ô∏è –°–µ—Ä–≤–µ—Ä –ø–µ—Ä–µ–≥—Ä—É–∂–µ–Ω ({process_count} –ø—Ä–æ—Ü–µ—Å—Å–æ–≤)")
    except Exception as e:
        logging.error(f"Failed to send overload message: {e}", exc_info=True)
        await message.answer("‚ö†Ô∏è –°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤")


# --- –°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å Python 3.8 ---
try:
    _to_thread = asyncio.to_thread
    async def run_in_thread(func, *args, **kwargs):
        return await _to_thread(func, *args, **kwargs)
except AttributeError:
    async def run_in_thread(func, *args, **kwargs):
        loop = asyncio.get_running_loop()
        return await loop.run_in_executor(None, func, *args, **kwargs)


# ---------------- –§–£–ù–ö–¶–ò–ò: –®–†–ò–§–¢–´ –ò –¢–ï–ö–°–¢ ----------------

def get_font(size: int) -> ImageFont.ImageFont:
    for font_path in FONT_PATHS:
        if os.path.exists(font_path):
            try:
                return ImageFont.truetype(font_path, size)
            except Exception:
                continue
    return ImageFont.load_default()

def get_unicode_font(size: int) -> ImageFont.ImageFont:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —à—Ä–∏—Ñ—Ç —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π Unicode"""
    for font_path in UNICODE_FONT_PATHS:
        if os.path.exists(font_path):
            try:
                return ImageFont.truetype(font_path, size)
            except Exception:
                continue
    return get_font(size)

def has_emoji(text: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ —Ç–µ–∫—Å—Ç —ç–º–æ–¥–∂–∏"""
    for char in text:
        code = ord(char)
        if (0x1F300 <= code <= 0x1F9FF or
            0x2600 <= code <= 0x26FF or
            0x2700 <= code <= 0x27BF or
            0xFE00 <= code <= 0xFE0F or
            0x1F000 <= code <= 0x1F02F or
            0x1F0A0 <= code <= 0x1F0FF or
            0x1F100 <= code <= 0x1F64F or
            0x1F680 <= code <= 0x1F6FF or
            0x1F900 <= code <= 0x1F9FF or
            0x1FA00 <= code <= 0x1FA6F or
            0x1FA70 <= code <= 0x1FAFF or
            0x2300 <= code <= 0x23FF or
            0x25A0 <= code <= 0x25FF):
            return True
    return False

def fit_text(text: str, font: ImageFont.ImageFont, max_width: int, img: Image.Image):
    """–†–∞–∑–±–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ —Å—Ç—Ä–æ–∫–∏ —Å —É—á–µ—Ç–æ–º pilmoji"""
    lines = []
    words = text.split()
    current_line = ""
    
    with Pilmoji(img) as pilmoji:
        for word in words:
            if len(lines) >= 10:
                break

            test_line = (current_line + " " + word).strip()
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º pilmoji –¥–ª—è –∏–∑–º–µ—Ä–µ–Ω–∏—è
            bbox = pilmoji.getsize(test_line, font=font)
            w = bbox[0]

            if w <= max_width:
                current_line = test_line
            else:
                if current_line:
                    lines.append(current_line)
                    current_line = word
                else:
                    current_line = word

    if current_line:
        lines.append(current_line)

    return lines if lines else ["..."]

def cleanup_old_temp_files():
    """–£–¥–∞–ª—è–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã —Å—Ç–∞—Ä—à–µ 1 —á–∞—Å–∞"""
    try:
        import time
        current_time = time.time()
        count = 0
        
        for filename in os.listdir("."):
            if filename.startswith("temp_"):
                filepath = os.path.join(".", filename)
                try:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–æ–∑—Ä–∞—Å—Ç —Ñ–∞–π–ª–∞
                    file_age = current_time - os.path.getmtime(filepath)
                    
                    # –ï—Å–ª–∏ —Å—Ç–∞—Ä—à–µ 1 —á–∞—Å–∞ (3600 —Å–µ–∫)
                    if file_age > 3600:
                        os.remove(filepath)
                        count += 1
                except:
                    pass
        
        if count > 0:
            logging.info(f"Cleaned up {count} old temp files")
    except Exception as e:
        logging.error(f"Cleanup error: {e}")


def generate_text_image(text: str, output_path: str, size=(600, 600)) -> bool:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫–∞—Ä—Ç–∏–Ω–∫—É –∏–∑ —Ç–µ–∫—Å—Ç–∞ –∏–ª–∏ —ç–º–æ–¥–∂–∏ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —Ü–≤–µ—Ç–Ω—ã—Ö —ç–º–æ–¥–∂–∏"""
    try:
        img = Image.new("RGB", size, "white")
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω—É–∂–µ–Ω –ª–∏ Unicode —à—Ä–∏—Ñ—Ç
        use_unicode = has_emoji(text)
        
        # –ü–æ–¥–±–∏—Ä–∞–µ–º —Ä–∞–∑–º–µ—Ä —à—Ä–∏—Ñ—Ç–∞
        max_font_size = 120
        min_font_size = 40
        
        best_font = None
        best_lines = []
        
        for font_size in range(max_font_size, min_font_size, -10):
            font = get_unicode_font(font_size) if use_unicode else get_font(font_size)
            lines = fit_text(text, font, size[0] - 40, img)
            
            # –°—á–∏—Ç–∞–µ–º –æ–±—â—É—é –≤—ã—Å–æ—Ç—É
            total_height = len(lines) * (font_size + 10)
            
            if total_height < size[1] - 40:
                best_font = font
                best_lines = lines
                break
        
        if not best_font:
            best_font = get_unicode_font(min_font_size) if use_unicode else get_font(min_font_size)
            best_lines = fit_text(text, best_font, size[0] - 40, img)
        
        # –†–∏—Å—É–µ–º —Ç–µ–∫—Å—Ç —Å —ç–º–æ–¥–∂–∏
        font_size = best_font.size
        total_height = len(best_lines) * (font_size + 10)
        y = (size[1] - total_height) / 2
        
        with Pilmoji(img) as pilmoji:
            for line in best_lines:
                bbox = pilmoji.getsize(line, font=best_font)
                line_w = bbox[0]
                x = (size[0] - line_w) / 2
                pilmoji.text((int(x), int(y)), line, font=best_font, fill="black")
                y += font_size + 10
        
        img.save(output_path, quality=95)
        return True
    except Exception as e:
        logging.error(f"Error generating text image: {e}", exc_info=True)
        return False


# ---------------- –§–£–ù–ö–¶–ò–ò: –û–ë–†–ê–ë–û–¢–ö–ê –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–ô ----------------

def apply_invert(img_path: str, output_path: str) -> bool:
    """–ò–Ω–≤–µ—Ä—Å–∏—è —Ü–≤–µ—Ç–æ–≤"""
    try:
        img = Image.open(img_path)
        if img.mode == 'RGBA':
            r, g, b, a = img.split()
            rgb = Image.merge('RGB', (r, g, b))
            rgb = ImageOps.invert(rgb)
            r2, g2, b2 = rgb.split()
            img = Image.merge('RGBA', (r2, g2, b2, a))
        else:
            img = img.convert('RGB')
            img = ImageOps.invert(img)
        
        img.save(output_path, quality=95)
        return True
    except Exception as e:
        logging.error(f"Invert error: {e}")
        return False

def apply_vintage(img_path: str, output_path: str) -> bool:
    """–í–∏–Ω—Ç–∞–∂–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞: —Å–µ–ø–∏—è + —à—É–º + –≤–∏–Ω—å–µ—Ç–∫–∞"""
    try:
        img = Image.open(img_path).convert('RGB')
        width, height = img.size
        
        # 1. –°–µ–ø–∏—è
        sepia_matrix = (
            0.393, 0.769, 0.189, 0,
            0.349, 0.686, 0.168, 0,
            0.272, 0.534, 0.131, 0
        )
        img = img.convert("RGB", sepia_matrix)
        
        # 2. –°–Ω–∏–∂–∞–µ–º –∫–æ–Ω—Ç—Ä–∞—Å—Ç –∏ –Ω–∞—Å—ã—â–µ–Ω–Ω–æ—Å—Ç—å
        enhancer = ImageEnhance.Contrast(img)
        img = enhancer.enhance(0.8)
        
        enhancer = ImageEnhance.Color(img)
        img = enhancer.enhance(0.6)
        
        # 3. –î–æ–±–∞–≤–ª—è–µ–º —à—É–º
        pixels = img.load()
        for i in range(0, width, 3):
            for j in range(0, height, 3):
                noise = random.randint(-15, 15)
                r, g, b = pixels[i, j]
                pixels[i, j] = (
                    max(0, min(255, r + noise)),
                    max(0, min(255, g + noise)),
                    max(0, min(255, b + noise))
                )
        
        # 4. –í–∏–Ω—å–µ—Ç–∫–∞
        vignette = Image.new('L', (width, height), 0)
        vignette_draw = ImageDraw.Draw(vignette)
        
        for i in range(min(width, height) // 2):
            darkness = int(255 * (i / (min(width, height) / 2)))
            vignette_draw.rectangle(
                [i, i, width - i, height - i],
                outline=darkness
            )
        
        img = Image.composite(img, Image.new('RGB', img.size, (40, 30, 20)), vignette)
        
        img.save(output_path, quality=95)
        return True
    except Exception as e:
        logging.error(f"Vintage error: {e}")
        return False

#–≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞

def generate_demotivator_text() -> str:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —É–º–Ω—É—é/—Å–∞—Ä–∫–∞—Å—Ç–∏—á–Ω—É—é —Ñ—Ä–∞–∑—É –¥–ª—è –¥–µ–º–æ—Ç–∏–≤–∞—Ç–æ—Ä–∞"""
    if not groq_client:
        return random.choice([
            "–ñ–∏–∑–Ω—å - –±–æ–ª—å",
            "–í—Å—ë —Ç–ª–µ–Ω–Ω–æ",
            "–ù–∏—á–µ–≥–æ –Ω–µ –≤–µ—á–Ω–æ",
            "–ù–∞–¥–µ–∂–¥–∞ —É–º–∏—Ä–∞–µ—Ç –ø–æ—Å–ª–µ–¥–Ω–µ–π",
        ])
    
    try:
        prompts = [
            # "–ù–∞–ø–∏—à–∏ –∫–æ—Ä–æ—Ç–∫—É—é —Å–∞—Ä–∫–∞—Å—Ç–∏—á–µ—Å–∫—É—é —Ñ—Ä–∞–∑—É –¥–ª—è –¥–µ–º–æ—Ç–∏–≤–∞—Ç–æ—Ä–∞ –Ω–∞ —Ä—É—Å—Å–∫–æ–º. –ú–∞–∫—Å–∏–º—É–º 8 —Å–ª–æ–≤. –¢–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç, –±–µ–∑ –∫–∞–≤—ã—á–µ–∫.",
            # "–ü—Ä–∏–¥—É–º–∞–π —Ñ–∏–ª–æ—Å–æ—Ñ—Å–∫—É—é —Ñ—Ä–∞–∑—É –¥–ª—è –º–µ–º–∞ –Ω–∞ —Ä—É—Å—Å–∫–æ–º. –ú–∞–∫—Å–∏–º—É–º 8 —Å–ª–æ–≤. –¢–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç.",
            # "–°–≥–µ–Ω–µ—Ä–∏—Ä—É–π —Ü–∏–Ω–∏—á–Ω—É—é –º—ã—Å–ª—å –¥–ª—è –¥–µ–º–æ—Ç–∏–≤–∞—Ç–æ—Ä–∞. –ö–æ—Ä–æ—Ç–∫–æ, –Ω–∞ —Ä—É—Å—Å–∫–æ–º, –¥–æ 8 —Å–ª–æ–≤.",
            # "–ù–∞–ø–∏—à–∏ –∞–±—Å—É—Ä–¥–Ω—É—é —Ñ—Ä–∞–∑—É –≤ —Å—Ç–∏–ª–µ —Ä—É—Å—Å–∫–∏—Ö –¥–µ–º–æ—Ç–∏–≤–∞—Ç–æ—Ä–æ–≤. –î–æ 8 —Å–ª–æ–≤.",
            "–Ω–∞–ø–∏—à–∏ –∫–∞–∫–æ–π-–Ω–∏–±—É–¥—å —Ä–æ—Ñ–ª —Ä–æ—Ñ–ª—è–Ω—Å–∫–∏–π",
            "–Ω–∞–ø–∏—à–∏ –∫–∞–∫—É—é-–Ω–∏–±—É–¥—å —à–∏–∑—É –¥–æ 8 —Å–ª–æ–≤",
        ]
        
        response = groq_client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=[
                {"role": "system", "content": "–¢—ã –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –¥–µ–º–æ—Ç–∏–≤–∞—Ç–æ—Ä–æ–≤. –ü–∏—à–∏ –∫—Ä–∞—Ç–∫–æ, —Å–∞—Ä–∫–∞—Å—Ç–∏—á–Ω–æ, –ø–æ-—Ä—É—Å—Å–∫–∏."},
                {"role": "user", "content": random.choice(prompts)}
            ],
            max_tokens=50,
            temperature=1.2,  # –ë–æ–ª—å—à–µ –∫—Ä–µ–∞—Ç–∏–≤–∞
        )
        
        text = response.choices[0].message.content.strip()
        
        # –£–±–∏—Ä–∞–µ–º –∫–∞–≤—ã—á–∫–∏ –µ—Å–ª–∏ –µ—Å—Ç—å
        text = text.strip('"').strip("'").strip()
        
        # –ï—Å–ª–∏ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π - –±–µ—Ä—ë–º –ø–µ—Ä–≤—ã–µ 10 —Å–ª–æ–≤
        words = text.split()
        if len(words) > 10:
            text = " ".join(words[:10]) + "..."
        
        logging.info(f"Generated text: {text}")
        return text
        
    except Exception as e:
        logging.error(f"Groq generation error: {e}")
        return random.choice([
            "–í—Å—ë —Å–ª–æ–∂–Ω–æ",
            "–ë—ã–≤–∞–µ—Ç",
            "–ñ–∏–∑–Ω—å - –±–æ–ª—å",
            "–ù–∏—á–µ–≥–æ –Ω–µ –≤–µ—á–Ω–æ",
        ])


def trumpify_text(original_text: str) -> str:
    """–ü–µ—Ä–µ–ø–∏—Å—ã–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –≤ —Å—Ç–∏–ª–µ –î–æ–Ω–∞–ª—å–¥–∞ –¢—Ä–∞–º–ø–∞"""
    if not groq_client:
        return f"{original_text} Tremendous! üá∫üá∏"
    
    try:
        prompt = f"""–ü–µ—Ä–µ–ø–∏—à–∏ —Ç–µ–∫—Å—Ç –≤ —Å—Ç–∏–ª–µ —Ç–≤–∏—Ç–æ–≤ –î–æ–Ω–∞–ª—å–¥–∞ –¢—Ä–∞–º–ø–∞. –¢–æ—á–Ω–æ –∫–æ–ø–∏—Ä—É–π –µ–≥–æ –º–∞–Ω–µ—Ä—É!

–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–´–ï —ç–ª–µ–º–µ–Ω—Ç—ã —Å—Ç–∏–ª—è:
- –ó–ê–ì–õ–ê–í–ù–´–ï —Å–ª–æ–≤–∞ –¥–ª—è —É—Å–∏–ª–µ–Ω–∏—è (VERY, GREAT, FAKE NEWS, TERRIBLE, etc)
- –ü—Ä–µ–≤–æ—Å—Ö–æ–¥–Ω—ã–µ —Å—Ç–µ–ø–µ–Ω–∏: biggest, greatest, best, worst, most, tremendous, fantastic, incredible, beautiful
- –ö–æ—Ä–æ—Ç–∫–∏–µ —Ä–µ–∑–∫–∏–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è. –ú–Ω–æ–≥–æ –≤–æ—Å–∫–ª–∏—Ü–∞—Ç–µ–ª—å–Ω—ã—Ö –∑–Ω–∞–∫–æ–≤!
- –§—Ä–∞–∑—ã: "Many people are saying", "Believe me", "Everyone knows", "Like never before"
- –ú–µ—Å—Ç–æ–∏–º–µ–Ω–∏—è: "I", "We", "They" (–≤—Ä–∞–≥–∏)
- –¢—Ä–µ—Ç—å–µ –ª–∏—Ü–æ –æ —Å–µ–±–µ: "President Trump", "Your favorite President"
- –≠–º–æ–¥–∑–∏: üá∫üá∏ (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ 1-2 —Ä–∞–∑–∞)
- –î—Ä–∞–º–∞—Ç–∏–∑–º –∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
- –û–±–≤–∏–Ω–µ–Ω–∏—è –≤—Ä–∞–≥–æ–≤ –≤ –ø—Ä–æ–≤–∞–ª–∞—Ö

–ü–†–ò–ú–ï–†–´ —Å—Ç–∏–ª—è –¢—Ä–∞–º–ø–∞:
"Just had a GREAT meeting with world leaders. Many people saying it was the BEST meeting in history! America is WINNING again! üá∫üá∏"

"The Fake News Media won't report this, but our economy is doing TREMENDOUSLY! Jobs up, unemployment DOWN. Best numbers EVER! üá∫üá∏"

"I am doing a FANTASTIC job - everyone knows it. The haters and losers won't admit it, but history will remember! MAGA! üá∫üá∏"

–û—Ä–∏–≥–∏–Ω–∞–ª: "{original_text}"

–û—Ç–≤–µ—Ç (—Ç–æ–ª—å–∫–æ –ø–µ—Ä–µ–ø–∏—Å–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –±–µ–∑ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤):"""

        response = groq_client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=[
                {"role": "system", "content": "You write EXACTLY like Donald Trump tweets. Use his style: CAPS, superlatives, short sentences, confidence, drama. Add 1-2 üá∫üá∏ flags."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=350,
            temperature=1.0,
        )
        
        result = response.choices[0].message.content.strip()
        result = result.strip('"').strip("'").strip()
        
        # –£–±–∏—Ä–∞–µ–º markdown –µ—Å–ª–∏ –µ—Å—Ç—å
        result = result.replace('**', '')
        
        logging.info(f"Trumpified: {original_text[:50]}")
        return result
        
    except Exception as e:
        logging.error(f"Trumpify error: {e}")
        return f"{original_text} - FAKE NEWS! üá∫üá∏"


async def download_user_avatar(user_id: int, output_path: str) -> bool:
    """–°–∫–∞—á–∏–≤–∞–µ—Ç –∞–≤–∞—Ç–∞—Ä–∫—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    try:
        photos = await bot.get_user_profile_photos(user_id, limit=1)
        if photos.total_count > 0:
            await bot.download(photos.photos[0][-1], destination=output_path)
            return True
        return False
    except Exception as e:
        logging.error(f"Failed to download avatar: {e}")
        return False


def create_trump_tweet_image(text: str, output_path: str, avatar_path: str = None) -> bool:
    """–°–æ–∑–¥–∞—ë—Ç –∫–∞—Ä—Ç–∏–Ω–∫—É —Ç–≤–∏—Ç–∞ –¢—Ä–∞–º–ø–∞ —Å –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–º —Ä–∞–∑–º–µ—Ä–æ–º"""
    try:
        from PIL import Image, ImageDraw, ImageFont
        from pilmoji import Pilmoji
        
        logging.info(f"Creating Trump tweet image: {output_path}")
        
        # –®—Ä–∏—Ñ—Ç—ã (–∑–∞–≥—Ä—É–∂–∞–µ–º —Å–Ω–∞—á–∞–ª–∞ –¥–ª—è –ø–æ–¥—Å—á—ë—Ç–∞ —Ä–∞–∑–º–µ—Ä–∞)
        try:
            font_name = ImageFont.truetype("/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf", 18)
            font_username = ImageFont.truetype("/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf", 15)
            font_text = ImageFont.truetype("/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf", 17)
        except:
            font_name = ImageFont.load_default()
            font_username = ImageFont.load_default()
            font_text = ImageFont.load_default()
        
        # === –í–´–ß–ò–°–õ–Ø–ï–ú –†–ê–ó–ú–ï–† ===
        max_width = 520
        
        # –†–∞–∑–±–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç –Ω–∞ —Å—Ç—Ä–æ–∫–∏
        words = text.split()
        lines = []
        current_line = []
        
        temp_img = Image.new('RGB', (1, 1))
        with Pilmoji(temp_img) as pilmoji:
            for word in words:
                test_line = ' '.join(current_line + [word])
                bbox = pilmoji.getsize(test_line, font=font_text)
                width = bbox[0]
                
                if width <= max_width:
                    current_line.append(word)
                else:
                    if current_line:
                        lines.append(' '.join(current_line))
                    current_line = [word]
            
            if current_line:
                lines.append(' '.join(current_line))
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º 15 —Å—Ç—Ä–æ–∫–∞–º–∏ –º–∞–∫—Å–∏–º—É–º
        lines = lines[:15]
        
        # –í—ã—á–∏—Å–ª—è–µ–º –≤—ã—Å–æ—Ç—É
        header_height = 100  # –ê–≤–∞—Ç–∞—Ä–∫–∞ + –∏–º—è
        text_height = len(lines) * 26
        footer_height = 80   # "just now" + –∏–∫–æ–Ω–∫–∏ + –æ—Ç—Å—Ç—É–ø—ã
        padding = 50         # –í–µ—Ä—Ö –∏ –Ω–∏–∑
        
        total_height = header_height + text_height + footer_height + padding
        img_height = total_height
        img_width = 600
        
        # –°–æ–∑–¥–∞—ë–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω—É–∂–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞
        img = Image.new('RGB', (img_width, img_height), color='#15202b')
        
        # –¢–≤–∏—Ç —Ñ–æ–Ω
        tweet_height = img_height - 50
        tweet_box = Image.new('RGB', (560, tweet_height), color='white')
        img.paste(tweet_box, (20, 25))
        
        draw = ImageDraw.Draw(img)
        
        # –ê–≤–∞—Ç–∞—Ä–∫–∞
        avatar_size = 48
        avatar_x, avatar_y = 40, 45
        
        if avatar_path and os.path.exists(avatar_path):
            try:
                avatar_img = Image.open(avatar_path).convert('RGB')
                avatar_img = avatar_img.resize((avatar_size, avatar_size), Image.LANCZOS)
                
                mask = Image.new('L', (avatar_size, avatar_size), 0)
                mask_draw = ImageDraw.Draw(mask)
                mask_draw.ellipse([0, 0, avatar_size, avatar_size], fill=255)
                
                img.paste(avatar_img, (avatar_x, avatar_y), mask)
            except Exception as e:
                logging.error(f"Avatar error: {e}")
                draw.ellipse([avatar_x, avatar_y, avatar_x + avatar_size, avatar_y + avatar_size], fill='#1d9bf0')
        else:
            draw.ellipse([avatar_x, avatar_y, avatar_x + avatar_size, avatar_y + avatar_size], fill='#1d9bf0')
        
        # –ò–º—è –∏ –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è
        draw.text((100, 50), "Donald J. Trump", font=font_name, fill='#0f1419')
        
        check_x, check_y = 270, 52
        draw.ellipse([check_x, check_y, check_x + 16, check_y + 16], fill='#1d9bf0')
        draw.text((check_x + 3, check_y - 1), "‚úì", font=font_username, fill='white')
        
        draw.text((100, 72), "@realDonaldTrump", font=font_username, fill='#536471')
        
        # –¢–µ–∫—Å—Ç —Å —ç–º–æ–¥–∂–∏
        y_pos = 115
        
        with Pilmoji(img) as pilmoji:
            for line in lines:
                pilmoji.text((40, y_pos), line, font=font_text, fill='#0f1419')
                y_pos += 26
        
        # –í—Ä–µ–º—è
        draw.text((40, y_pos + 20), "just now", font=font_username, fill='#536471')
        
        # –ò–∫–æ–Ω–∫–∏ –≤–Ω–∏–∑—É (–¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∞—è –ø–æ–∑–∏—Ü–∏—è)
        icons_y = img_height - 45
        icon_color = '#536471'
        icon_size = 18
        
        # Reply
        x1 = 50
        draw.ellipse([x1, icons_y, x1 + icon_size, icons_y + icon_size], outline=icon_color, width=2)
        draw.polygon([(x1 + 3, icons_y + icon_size), (x1 + 3, icons_y + icon_size + 4), (x1 + 7, icons_y + icon_size)], fill=icon_color)
        
        # Retweet
        x2 = 140
        draw.line([(x2, icons_y + 6), (x2 + 14, icons_y + 6)], fill=icon_color, width=2)
        draw.polygon([(x2 + 14, icons_y + 3), (x2 + 18, icons_y + 6), (x2 + 14, icons_y + 9)], fill=icon_color)
        draw.line([(x2, icons_y + 12), (x2 + 14, icons_y + 12)], fill=icon_color, width=2)
        draw.polygon([(x2, icons_y + 9), (x2 - 4, icons_y + 12), (x2, icons_y + 15)], fill=icon_color)
        
        # Like
        x3 = 230
        draw.ellipse([x3, icons_y + 2, x3 + 7, icons_y + 9], outline=icon_color, width=2)
        draw.ellipse([x3 + 7, icons_y + 2, x3 + 14, icons_y + 9], outline=icon_color, width=2)
        draw.polygon([(x3, icons_y + 7), (x3 + 14, icons_y + 7), (x3 + 7, icons_y + 16)], outline=icon_color, width=2)
        
        # Share
        x4 = 320
        draw.rectangle([x4 + 3, icons_y + 8, x4 + 13, icons_y + 16], outline=icon_color, width=2)
        draw.line([(x4 + 8, icons_y + 8), (x4 + 8, icons_y + 2)], fill=icon_color, width=2)
        draw.polygon([(x4 + 5, icons_y + 4), (x4 + 8, icons_y), (x4 + 11, icons_y + 4)], fill=icon_color)
        
        # Bookmark
        x5 = 410
        draw.rectangle([x5, icons_y + 2, x5 + 12, icons_y + 18], outline=icon_color, width=2)
        draw.polygon([(x5, icons_y + 18), (x5 + 6, icons_y + 14), (x5 + 12, icons_y + 18)], fill=icon_color)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º
        img.save(output_path)
        
        logging.info(f"Trump tweet created: {img_width}x{img_height}, {len(lines)} lines")
        return os.path.exists(output_path)
        
    except Exception as e:
        logging.error(f"Tweet image error: {e}", exc_info=True)
        return False


# ---------------- –§–£–ù–ö–¶–ò–ò: –û–ë–†–ê–ë–û–¢–ö–ê –ú–ï–î–ò–ê ----------------

def extract_first_frame(video_path: str, output_jpg: str) -> bool:
    """–î–æ—Å—Ç–∞–µ–º 1 –∫–∞–¥—Ä"""
    cmd = [
        "ffmpeg", "-y",
        "-i", video_path,
        "-vframes", "1",
        "-q:v", "2",
        output_jpg
    ]
    result = subprocess.run(cmd, capture_output=True, check=False)
    return os.path.exists(output_jpg) and os.path.getsize(output_jpg) > 0

def build_layout_params(base_w, base_h, text, for_video=False):
    """–°–æ–∑–¥–∞–µ—Ç —Ñ–æ–Ω —Å —Ä–∞–º–∫–æ–π –∏ —Ç–µ–∫—Å—Ç–æ–º"""
    target_w, target_h = base_w, base_h

    max_side = 720 if for_video else 1024

    if max(target_w, target_h) > max_side:
        ratio = max_side / max(target_w, target_h)
        target_w = int(target_w * ratio)
        target_h = int(target_h * ratio)

    if for_video:
        target_w = (target_w // 2) * 2
        target_h = (target_h // 2) * 2

    pad_top = 40
    pad_side = 40
    gap_to_text = 50
    gap_after_text = 40

    total_w = target_w + pad_side * 2

    font_size = max(20, int(total_w / 12))
    font = get_unicode_font(font_size) if has_emoji(text) else get_font(font_size)

    temp_img = Image.new("RGB", (1, 1))
    lines = fit_text(text, font, total_w - 20, temp_img)

    text_block_h = len(lines) * (font_size + 10)
    pad_bottom = gap_to_text + text_block_h + gap_after_text

    total_h = target_h + pad_top + pad_bottom
    
    # === –î–û–ë–ê–í–¨ –≠–¢–û ===
    # –û–∫—Ä—É–≥–ª—è–µ–º –¥–æ —á—ë—Ç–Ω—ã—Ö –¥–ª—è –≤–∏–¥–µ–æ
    if for_video:
        total_w = (total_w // 2) * 2
        total_h = (total_h // 2) * 2
    # === –ö–û–ù–ï–¶ ===

    canvas = Image.new("RGB", (total_w, total_h), "black")
    draw = ImageDraw.Draw(canvas)

    # –†–∞–º–∫–∞
    border = 2
    draw.rectangle(
        [(pad_side - 5, pad_top - 5),
         (pad_side + target_w + 4, pad_top + target_h + 4)],
        outline="white", width=border
    )

    # –†–∏—Å—É–µ–º —Ç–µ–∫—Å—Ç —Å —ç–º–æ–¥–∂–∏
    y_text = pad_top + target_h + gap_to_text
    
    with Pilmoji(canvas) as pilmoji:
        for line in lines:
            bbox = pilmoji.getsize(line, font=font)
            line_w = bbox[0]
            x_text = (total_w - line_w) / 2
            pilmoji.text((int(x_text), int(y_text)), line, font=font, fill="white")
            y_text += font_size + 10

    return canvas, target_w, target_h, pad_side, pad_top


def create_demotivator_image(img_path, text, output_path, is_avatar=False, effect=None):
    """–°–æ–∑–¥–∞—ë—Ç –¥–µ–º–æ—Ç–∏–≤–∞—Ç–æ—Ä –∏–∑ –∫–∞—Ä—Ç–∏–Ω–∫–∏"""
    try:
        orig = Image.open(img_path).convert("RGBA")

        if is_avatar or max(orig.size) < 300:
            orig = orig.resize((600, 600), Image.Resampling.LANCZOS)

        # –ü—Ä–∏–º–µ–Ω—è–µ–º —ç—Ñ—Ñ–µ–∫—Ç
        if effect == 'invert':
            temp_path = img_path + "_temp.png"
            orig.save(temp_path)
            if apply_invert(temp_path, temp_path):
                orig = Image.open(temp_path).convert("RGBA")
            try:
                os.remove(temp_path)
            except:
                pass
        elif effect == 'vintage':
            temp_path = img_path + "_temp.png"
            orig.save(temp_path)
            if apply_vintage(temp_path, temp_path):
                orig = Image.open(temp_path).convert("RGBA")
            try:
                os.remove(temp_path)
            except:
                pass

        bg, t_w, t_h, p_x, p_y = build_layout_params(orig.width, orig.height, text, for_video=False)

        orig = orig.resize((t_w, t_h), Image.Resampling.LANCZOS)

        bg_rgba = bg.convert("RGBA")
        bg_rgba.paste(orig, (p_x, p_y), orig)

        bg_rgba.convert("RGB").save(output_path, quality=95)
        return True
    except Exception as e:
        logging.error(f"Image error: {e}", exc_info=True)
        return False

def convert_tgs_to_mp4_simple(tgs_path: str, output_mp4: str) -> bool:
    """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è TGS —á–µ—Ä–µ–∑ lottie + ffmpeg"""
    logging.info(f"TGS conversion started: {tgs_path} -> {output_mp4}")
    
    try:
        import gzip
        import json
        import tempfile
        import shutil
        from lottie import parsers
        from lottie.exporters.cairo import export_png
        
        logging.info("Libraries imported successfully")
        
        # –†–∞—Å–ø–∞–∫–æ–≤—ã–≤–∞–µ–º
        with gzip.open(tgs_path, 'rb') as f:
            data = json.load(f)
            logging.info("TGS file unpacked")
            anim = parsers.tgs.parse_tgs(data)
            logging.info(f"Animation parsed: duration={anim.out_point/anim.frame_rate}s")
        
        temp_dir = tempfile.mkdtemp()
        logging.info(f"Temp dir created: {temp_dir}")
        
        try:
            # –†–µ–Ω–¥–µ—Ä–∏–º –∫–∞–¥—Ä—ã
            fps = 30
            duration = anim.out_point / anim.frame_rate
            frame_count = int(duration * fps)
            
            logging.info(f"Rendering {frame_count} frames at {fps} fps...")
            
            for i in range(min(frame_count, 90)):  # –ú–∞–∫—Å 3 —Å–µ–∫
                if i % 10 == 0:
                    logging.info(f"Rendering frame {i}/{frame_count}")
                
                t = (i / fps) * anim.frame_rate
                frame_path = f"{temp_dir}/{i:04d}.png"
                export_png(anim, frame_path, t, 512, 512)
            
            logging.info("All frames rendered, starting ffmpeg...")
            
            # –°–æ–±–∏—Ä–∞–µ–º –≤ MP4
            cmd = [
                "ffmpeg", "-y",
                "-framerate", str(fps),
                "-i", f"{temp_dir}/%04d.png",
                "-c:v", "libx264",
                "-pix_fmt", "yuv420p",
                "-movflags", "+faststart",
                "-t", "3",
                output_mp4
            ]
            result = subprocess.run(cmd, capture_output=True, check=False)
            
            if result.returncode != 0:
                logging.error(f"FFmpeg error: {result.stderr.decode()}")
                return False
            
            logging.info(f"TGS conversion completed: {output_mp4}")
            return os.path.exists(output_mp4) and os.path.getsize(output_mp4) > 1000
            
        finally:
            logging.info(f"Cleaning up temp dir: {temp_dir}")
            shutil.rmtree(temp_dir, ignore_errors=True)
            
    except Exception as e:
        logging.error(f"TGS mp4 error: {e}", exc_info=True)
        return False

def convert_tgs_to_mp4(tgs_path: str, output_path: str) -> bool:
    """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç TGS —Å—Ç–∏–∫–µ—Ä –≤ MP4"""
    try:
        import gzip
        import json
        
        # –†–∞—Å–ø–∞–∫–æ–≤—ã–≤–∞–µ–º TGS –≤ JSON
        json_path = tgs_path.replace('.tgs', '.json')
        with gzip.open(tgs_path, 'rb') as f_in:
            with open(json_path, 'w') as f_out:
                json.dump(json.load(f_in), f_out)
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —á–µ—Ä–µ–∑ ffmpeg —Å lottie filter (–µ—Å–ª–∏ –µ—Å—Ç—å)
        # –ò–ª–∏ –ø—Ä–æ—Å—Ç–æ –¥–µ–ª–∞–µ–º –∏–∑ –ø—Ä–µ–≤—å—é –≤–∏–¥–µ–æ
        cmd = [
            "ffmpeg", "-y",
            "-f", "lavfi",
            "-i", f"color=c=white:s=512x512:d=3",
            "-vf", f"drawtext=text='Animated Sticker':fontsize=48:fontcolor=black:x=(w-text_w)/2:y=(h-text_h)/2",
            "-c:v", "libx264",
            "-pix_fmt", "yuv420p",
            "-t", "3",
            output_path
        ]
        
        result = subprocess.run(cmd, capture_output=True, check=False)
        
        # Cleanup
        if os.path.exists(json_path):
            os.remove(json_path)
        
        return os.path.exists(output_path) and os.path.getsize(output_path) > 1000
        
    except Exception as e:
        logging.error(f"TGS conversion error: {e}")
        return False

def create_demotivator_video(vid_path, text, output_path):
    """–°–æ–∑–¥–∞–µ—Ç –≤–∏–¥–µ–æ-–¥–µ–º–æ—Ç–∏–≤–∞—Ç–æ—Ä"""
    frame_path = vid_path + ".jpg"
    bg_path = vid_path + "_bg.png"

    try:
        logging.info(f"Video demotivator: input={vid_path}, output={output_path}")
        
        if not extract_first_frame(vid_path, frame_path):
            logging.error("Failed to extract first frame")
            return False

        frame = Image.open(frame_path)
        w, h = frame.size
        logging.info(f"Video dimensions: {w}x{h}")

        bg, t_w, t_h, p_x, p_y = build_layout_params(w, h, text, for_video=True)
        bg.save(bg_path)
        logging.info(f"Background created: {t_w}x{t_h}, offset: ({p_x}, {p_y})")

        filter_complex = (
            f"[1:v]scale={t_w}:{t_h}[vid];"
            f"[0:v][vid]overlay={p_x}:{p_y}:shortest=1"
        )

        cmd = [
            "ffmpeg", "-y",
            "-loop", "1", "-i", bg_path,
            "-i", vid_path,
            "-filter_complex", filter_complex,
            "-c:v", "libx264",
            "-preset", "ultrafast",
            "-crf", "20",
            "-pix_fmt", "yuv420p",
            "-t", "30",
            output_path
        ]

        logging.info("Starting ffmpeg with command: " + " ".join(cmd))
        result = subprocess.run(cmd, capture_output=True, check=False)

        if result.returncode != 0:
            logging.error(f"FFmpeg failed with code {result.returncode}")
            logging.error(f"FFmpeg stderr: {result.stderr.decode()}")
            return False

        if os.path.exists(output_path):
            size = os.path.getsize(output_path)
            logging.info(f"Output file created: {output_path}, size: {size} bytes")
            
            if size > 1000:
                return True
            else:
                logging.error(f"Output file too small: {size} bytes")
                return False
        else:
            logging.error("Output file not created")
            return False

    except Exception as e:
        logging.error(f"Video error: {e}", exc_info=True)
        return False
    finally:
        for f in [frame_path, bg_path]:
            if os.path.exists(f): 
                try:
                    os.remove(f)
                except:
                    pass


# ---------------- –•–ï–ù–î–õ–ï–†–´ ----------------

# === TENET FUNCTIONS ===

def mirror_image(img_path: str, output_path: str) -> bool:
    """Mirror an image horizontally."""
    try:
        img = Image.open(img_path)
        mirrored = img.transpose(Image.FLIP_LEFT_RIGHT)
        if mirrored.mode == "RGBA":
            mirrored = mirrored.convert("RGB")
        mirrored.save(output_path, "JPEG", quality=95)
        logging.info(f"Mirrored image saved to {output_path}")
        return True
    except Exception as e:
        logging.error(f"Mirror image error: {e}", exc_info=True)
        return False


def reverse_video(vid_path: str, output_path: str) -> bool:
    """Reverse a video or GIF (play backwards)."""
    try:
        max_duration = 30
        cmd = [
            "ffmpeg", "-y",
            "-i", vid_path,
            "-t", str(max_duration),
            "-vf", "reverse",
            "-af", "areverse",
            "-c:v", "libx264",
            "-preset", "ultrafast",
            "-crf", "23",
            "-c:a", "aac",
            "-b:a", "128k",
            "-movflags", "+faststart",
            "-pix_fmt", "yuv420p",
            output_path
        ]
        logging.info(f"Reversing video: {vid_path}")
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)
        
        if result.returncode != 0:
            cmd_no_audio = [
                "ffmpeg", "-y",
                "-i", vid_path,
                "-t", str(max_duration),
                "-vf", "reverse",
                "-c:v", "libx264",
                "-preset", "ultrafast",
                "-crf", "23",
                "-an",
                "-movflags", "+faststart",
                "-pix_fmt", "yuv420p",
                output_path
            ]
            result = subprocess.run(cmd_no_audio, capture_output=True, text=True, timeout=300)
            if result.returncode != 0:
                logging.error(f"FFmpeg reverse error: {result.stderr}")
                return False
        
        if os.path.exists(output_path) and os.path.getsize(output_path) > 0:
            logging.info(f"Reversed video saved to {output_path}")
            return True
        return False
    except subprocess.TimeoutExpired:
        logging.error("Video reverse timeout")
        return False
    except Exception as e:
        logging.error(f"Reverse video error: {e}", exc_info=True)
        return False


def reverse_text(text: str) -> str:
    """Reverse text fully."""
    return text[::-1]


def reverse_audio(audio_path: str, output_path: str) -> bool:
    """Reverse audio file."""
    try:
        cmd = [
            "ffmpeg", "-y",
            "-i", audio_path,
            "-af", "areverse",
            "-c:a", "libopus",
            "-b:a", "64k",
            output_path
        ]
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=120)
        if result.returncode != 0:
            logging.error(f"Audio reverse error: {result.stderr}")
            return False
        return os.path.exists(output_path) and os.path.getsize(output_path) > 0
    except Exception as e:
        logging.error(f"Reverse audio error: {e}")
        return False


def reverse_pdf(pdf_path: str, output_path: str) -> bool:
    """Reverse PDF page order."""
    try:
        from PyPDF2 import PdfReader, PdfWriter
        reader = PdfReader(pdf_path)
        writer = PdfWriter()
        for page in reversed(reader.pages):
            writer.add_page(page)
        with open(output_path, "wb") as f:
            writer.write(f)
        logging.info(f"Reversed PDF: {len(reader.pages)} pages")
        return True
    except ImportError:
        logging.error("PyPDF2 not installed")
        return False
    except Exception as e:
        logging.error(f"PDF reverse error: {e}")
        return False


@dp.message(Command("tenet"))
async def cmd_tenet(message: Message):
    """Handle /tenet command - reverse media, text, audio, PDF."""
    if not message.reply_to_message:
        await message.reply(
            "üîÑ *–ö–æ–º–∞–Ω–¥–∞ /tenet* ‚Äî –ø–µ—Ä–µ–≤–æ—Ä–∞—á–∏–≤–∞–µ—Ç –≤—Å—ë!\n\n"
            "–û—Ç–≤–µ—Ç—å –Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏–µ:\n"
            "‚Ä¢ üìù –¢–µ–∫—Å—Ç ‚Üí —å—Ç–∞—Ä–æ–±–æ|—Ç–µ–∫—Å—Ç –Ω–∞–æ–±–æ—Ä–æ—Ç\n"
            "‚Ä¢ üñº –§–æ—Ç–æ ‚Üí –∑–µ—Ä–∫–∞–ª–æ\n"
            "‚Ä¢ üé¨ –í–∏–¥–µ–æ/GIF ‚Üí –∑–∞–¥–æ–º –Ω–∞–ø–µ—Ä—ë–¥\n"
            "‚Ä¢ üé§ –ì–æ–ª–æ—Å–æ–≤–æ–µ ‚Üí —Ä–µ–≤–µ—Ä—Å –∞—É–¥–∏–æ\n"
            "‚Ä¢ üéµ –ê—É–¥–∏–æ ‚Üí —Ä–µ–≤–µ—Ä—Å\n"
            "‚Ä¢ üìÑ PDF ‚Üí —Å—Ç—Ä–∞–Ω–∏—Ü—ã –≤ –æ–±—Ä–∞—Ç–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ\n"
            "‚Ä¢ üìç –õ–æ–∫–∞—Ü–∏—è ‚Üí –∞–Ω—Ç–∏–ø–æ–¥ (–ø—Ä–æ—Ç–∏–≤–æ–ø–æ–ª–æ–∂–Ω–∞—è —Ç–æ—á–∫–∞ –ó–µ–º–ª–∏)",
            parse_mode="Markdown"
        )
        return

    replied = message.reply_to_message
    status_msg = await message.reply("‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤ —Å—Ç–∏–ª–µ –¢–µ–Ω–µ—Ç...")

    input_file = f"temp_tenet_in_{message.message_id}"
    output_file = f"temp_tenet_out_{message.message_id}"

    try:
        # === LOCATION (Antipode) ===
        if replied.location:
            lat = replied.location.latitude
            lon = replied.location.longitude

            # Calculate antipodal point (opposite side of Earth)
            anti_lat = -lat
            anti_lon = lon + 180 if lon <= 0 else lon - 180

            await status_msg.edit_text(
                f"üåç –ò—Å—Ö–æ–¥–Ω–∞—è —Ç–æ—á–∫–∞: {lat:.6f}, {lon:.6f}\n"
                f"üîÑ –ü—Ä–æ–±–∏–≤–∞–µ–º –ó–µ–º–ª—é –Ω–∞—Å–∫–≤–æ–∑—å...\n"
                f"üåè –ê–Ω—Ç–∏–ø–æ–¥: {anti_lat:.6f}, {anti_lon:.6f}"
            )

            await message.answer_location(latitude=anti_lat, longitude=anti_lon)
            return

        # === TEXT ===
        elif replied.text:
            reversed_text = reverse_text(replied.text)
            await status_msg.edit_text(f"üîÑ {reversed_text}")
            return

        # === PHOTO ===
        elif replied.photo:
            input_file += ".jpg"
            output_file += ".jpg"
            await bot.download(replied.photo[-1], destination=input_file)
            await status_msg.edit_text("‚è≥ –ó–µ—Ä–∫–∞–ª–∏–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ...")
            success = await run_in_thread(lambda: mirror_image(input_file, output_file))
            if success:
                await message.answer_photo(FSInputFile(output_file))
            else:
                await message.answer("–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–µ—Ä–∫–∞–ª–∏—Ä–æ–≤–∞–Ω–∏–∏")

        # === VOICE ===
        elif replied.voice:
            input_file += ".ogg"
            output_file += ".ogg"
            await bot.download(replied.voice, destination=input_file)
            await status_msg.edit_text("‚è≥ –ü–µ—Ä–µ–≤–æ—Ä–∞—á–∏–≤–∞–µ–º –≥–æ–ª–æ—Å–æ–≤–æ–µ...")
            success = await run_in_thread(lambda: reverse_audio(input_file, output_file))
            if success:
                await message.answer_voice(FSInputFile(output_file))
            else:
                await message.answer("–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–µ–≤–µ—Ä—Å–µ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ")

        # === AUDIO ===
        elif replied.audio:
            ext = ".mp3"
            if replied.audio.file_name:
                ext = os.path.splitext(replied.audio.file_name)[1] or ".mp3"
            input_file += ext
            output_file += ".ogg"
            await bot.download(replied.audio, destination=input_file)
            await status_msg.edit_text("‚è≥ –ü–µ—Ä–µ–≤–æ—Ä–∞—á–∏–≤–∞–µ–º –∞—É–¥–∏–æ...")
            success = await run_in_thread(lambda: reverse_audio(input_file, output_file))
            if success:
                await message.answer_audio(FSInputFile(output_file), title="Reversed Audio")
            else:
                await message.answer("–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–µ–≤–µ—Ä—Å–µ –∞—É–¥–∏–æ")

        # === DOCUMENT ===
        elif replied.document:
            mime = replied.document.mime_type or ""
            fname = replied.document.file_name or "file"
            
            # PDF
            if "pdf" in mime or fname.lower().endswith(".pdf"):
                input_file += ".pdf"
                output_file += ".pdf"
                await bot.download(replied.document, destination=input_file)
                await status_msg.edit_text("‚è≥ –ü–µ—Ä–µ–≤–æ—Ä–∞—á–∏–≤–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—ã PDF...")
                success = await run_in_thread(lambda: reverse_pdf(input_file, output_file))
                if success:
                    await message.answer_document(FSInputFile(output_file, filename="reversed.pdf"))
                else:
                    await message.answer("–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–µ–≤–µ—Ä—Å–µ PDF (–Ω—É–∂–µ–Ω PyPDF2)")
            
            # Image document
            elif "image" in mime:
                input_file += ".jpg"
                output_file += ".jpg"
                await bot.download(replied.document, destination=input_file)
                await status_msg.edit_text("‚è≥ –ó–µ—Ä–∫–∞–ª–∏–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ...")
                success = await run_in_thread(lambda: mirror_image(input_file, output_file))
                if success:
                    await message.answer_photo(FSInputFile(output_file))
                else:
                    await message.answer("–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–µ—Ä–∫–∞–ª–∏—Ä–æ–≤–∞–Ω–∏–∏")
            
            # Text file
            elif "text" in mime or fname.endswith((".txt", ".md", ".json", ".xml", ".html", ".css", ".js", ".py")):
                input_file += ".txt"
                await bot.download(replied.document, destination=input_file)
                with open(input_file, "r", encoding="utf-8", errors="ignore") as f:
                    content = f.read()
                reversed_content = reverse_text(content)
                if len(reversed_content) > 4000:
                    output_file += ".txt"
                    with open(output_file, "w", encoding="utf-8") as f:
                        f.write(reversed_content)
                    await message.answer_document(FSInputFile(output_file, filename=f"reversed_{fname}"))
                else:
                    await message.answer(f"```\n{reversed_content[:4000]}\n```", parse_mode="Markdown")

            # Video document
            elif "video" in mime:
                can_process, count = check_server_load()
                if not can_process:
                    await send_overload_message(message, count)
                    return
                input_file += ".mp4"
                output_file += ".mp4"
                await bot.download(replied.document, destination=input_file)
                await status_msg.edit_text("‚è≥ –ü–µ—Ä–µ–≤–æ—Ä–∞—á–∏–≤–∞–µ–º –≤–∏–¥–µ–æ...")
                success = await run_in_thread(lambda: reverse_video(input_file, output_file))
                if success:
                    await message.answer_video(FSInputFile(output_file))
                else:
                    await message.answer("–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–µ–≤–µ—Ä—Å–µ –≤–∏–¥–µ–æ")

            else:
                await message.answer(f"–ù–µ –∑–Ω–∞—é –∫–∞–∫ –ø–µ—Ä–µ–≤–µ—Ä–Ω—É—Ç—å —ç—Ç–æ—Ç —Ç–∏–ø —Ñ–∞–π–ª–∞: {mime}")

        # === VIDEO ===
        elif replied.video:
            can_process, count = check_server_load()
            if not can_process:
                await send_overload_message(message, count)
                return
            input_file += ".mp4"
            output_file += ".mp4"
            await bot.download(replied.video, destination=input_file)
            await status_msg.edit_text("‚è≥ –ü–µ—Ä–µ–≤–æ—Ä–∞—á–∏–≤–∞–µ–º –≤—Ä–µ–º—è...")
            success = await run_in_thread(lambda: reverse_video(input_file, output_file))
            if success:
                await message.answer_video(FSInputFile(output_file))
            else:
                await message.answer("–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–µ–≤–µ—Ä—Å–µ –≤–∏–¥–µ–æ")

        # === ANIMATION (GIF) ===
        elif replied.animation:
            can_process, count = check_server_load()
            if not can_process:
                await send_overload_message(message, count)
                return
            input_file += ".mp4"
            output_file += ".mp4"
            await bot.download(replied.animation, destination=input_file)
            await status_msg.edit_text("‚è≥ –ü–µ—Ä–µ–≤–æ—Ä–∞—á–∏–≤–∞–µ–º GIF...")
            success = await run_in_thread(lambda: reverse_video(input_file, output_file))
            if success:
                await message.answer_animation(FSInputFile(output_file))
            else:
                await message.answer("–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–µ–≤–µ—Ä—Å–µ GIF")

        # === VIDEO NOTE ===
        elif replied.video_note:
            can_process, count = check_server_load()
            if not can_process:
                await send_overload_message(message, count)
                return
            input_file += ".mp4"
            output_file += ".mp4"
            await bot.download(replied.video_note, destination=input_file)
            await status_msg.edit_text("‚è≥ –ü–µ—Ä–µ–≤–æ—Ä–∞—á–∏–≤–∞–µ–º –∫—Ä—É–∂–æ–∫...")
            success = await run_in_thread(lambda: reverse_video(input_file, output_file))
            if success:
                await message.answer_animation(FSInputFile(output_file))
            else:
                await message.answer("–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–µ–≤–µ—Ä—Å–µ –≤–∏–¥–µ–æ")

        # === STICKER ===
        elif replied.sticker:
            file_info = await bot.get_file(replied.sticker.file_id)
            file_path = file_info.file_path
            
            if file_path and file_path.endswith(".webm"):
                can_process, count = check_server_load()
                if not can_process:
                    await send_overload_message(message, count)
                    return
                input_file += ".webm"
                output_file += ".mp4"
                await bot.download(replied.sticker, destination=input_file)
                await status_msg.edit_text("‚è≥ –ü–µ—Ä–µ–≤–æ—Ä–∞—á–∏–≤–∞–µ–º –≤–∏–¥–µ–æ-—Å—Ç–∏–∫–µ—Ä...")
                success = await run_in_thread(lambda: reverse_video(input_file, output_file))
                if success:
                    await message.answer_animation(FSInputFile(output_file))
                else:
                    await message.answer("–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–µ–≤–µ—Ä—Å–µ —Å—Ç–∏–∫–µ—Ä–∞")
            elif file_path and (file_path.endswith(".webp") or file_path.endswith(".png")):
                input_file += ".webp"
                output_file += ".jpg"
                await bot.download(replied.sticker, destination=input_file)
                await status_msg.edit_text("‚è≥ –ó–µ—Ä–∫–∞–ª–∏–º —Å—Ç–∏–∫–µ—Ä...")
                success = await run_in_thread(lambda: mirror_image(input_file, output_file))
                if success:
                    await message.answer_photo(FSInputFile(output_file))
                else:
                    await message.answer("–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–µ—Ä–∫–∞–ª–∏—Ä–æ–≤–∞–Ω–∏–∏ —Å—Ç–∏–∫–µ—Ä–∞")
            elif file_path and file_path.endswith(".tgs"):
                await message.answer("TGS —Å—Ç–∏–∫–µ—Ä—ã –ø–æ–∫–∞ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è –¥–ª—è /tenet")
            else:
                await message.answer("–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø —Å—Ç–∏–∫–µ—Ä–∞")

        else:
            await message.answer("–ù–µ –º–æ–≥—É –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —ç—Ç–æ—Ç —Ç–∏–ø —Å–æ–æ–±—â–µ–Ω–∏—è")

    except Exception as e:
        logging.error(f"Tenet command error: {e}", exc_info=True)
        await message.answer("–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ")
    finally:
        try:
            await status_msg.delete()
        except:
            pass
        for f in [input_file, output_file]:
            if os.path.exists(f):
                try:
                    os.remove(f)
                except:
                    pass

# === END TENET ===
@dp.message(Command("trump", "—Ç—Ä–∞–º–ø"))
async def cmd_trump(message: Message):
    """–ü–µ—Ä–µ–ø–∏—Å–∞—Ç—å —Ç–µ–∫—Å—Ç –≤ —Å—Ç–∏–ª–µ –¢—Ä–∞–º–ø–∞ —Å –∫–∞—Ä—Ç–∏–Ω–∫–æ–π"""
    
    # –ò–∑ —Ä–µ–ø–ª–∞—è
    if message.reply_to_message:
        original = message.reply_to_message.text or message.reply_to_message.caption
        if not original:
            await message.answer("–ù–µ—Ç —Ç–µ–∫—Å—Ç–∞ –¥–ª—è —Ç—Ä–∞–º–ø–∏—Ñ–∏–∫–∞—Ü–∏–∏")
            return
        user_id = message.reply_to_message.from_user.id
    # –ò–∑ —Ç–µ–∫—Å—Ç–∞ –∫–æ–º–∞–Ω–¥—ã
    else:
        parts = message.text.split(maxsplit=1)
        if len(parts) < 2:
            await message.answer("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:\n/trump —Ç–µ–∫—Å—Ç\n–∏–ª–∏ –æ—Ç–≤–µ—Ç—å –Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏–µ")
            return
        original = parts[1]
        user_id = message.from_user.id
    
    status_msg = await message.reply("‚è≥ MAKING AMERICA GREAT AGAIN...")
    
    output_path = f"/root/bots/trump_tweet_{message.message_id}.png"
    avatar_path = f"/root/bots/trump_avatar_{message.message_id}.jpg"
    
    try:
        # –¢—Ä–∞–º–ø–∏—Ñ–∏—Ü–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç
        trumpified = await run_in_thread(lambda: trumpify_text(original))
        
        # –°–∫–∞—á–∏–≤–∞–µ–º –∞–≤–∞—Ç–∞—Ä–∫—É
        await download_user_avatar(user_id, avatar_path)
        
        # –°–æ–∑–¥–∞—ë–º –∫–∞—Ä—Ç–∏–Ω–∫—É
        if await run_in_thread(lambda: create_trump_tweet_image(trumpified, output_path, avatar_path)):
            await message.answer_photo(
                FSInputFile(output_path),
                caption="üá∫üá∏ **TRUMP MODE ACTIVATED** üá∫üá∏"
            )
        else:
            # Fallback –Ω–∞ —Ç–µ–∫—Å—Ç
            await message.answer(f"üá∫üá∏ **TRUMP MODE ACTIVATED** üá∫üá∏\n\n{trumpified}")
        
    except Exception as e:
        logging.error(f"Trump command error: {e}", exc_info=True)
        await message.answer("FAKE NEWS! –û—à–∏–±–∫–∞ —Ç—Ä–∞–º–ø–∏—Ñ–∏–∫–∞—Ü–∏–∏ üá∫üá∏")
    
    finally:
        try:
            await status_msg.delete()
        except:
            pass
        
        # –û—á–∏—Å—Ç–∫–∞
        for f in [output_path, avatar_path]:
            if os.path.exists(f):
                try:
                    os.remove(f)
                except:
                    pass


@dp.message(Command("help"))
async def cmd_help(message: Message):
    help_text = """
**–î–µ–º–æ—Ç–∏–≤–∞—Ç–æ—Ä –ë–æ—Ç —Å —Ü–≤–µ—Ç–Ω—ã–º–∏ —ç–º–æ–¥–∂–∏ üé®**

**–ö–æ–º–∞–Ω–¥—ã:**
/d [—Ç–µ–∫—Å—Ç] ‚Äî —Å–æ–∑–¥–∞—Ç—å –¥–µ–º–æ—Ç–∏–≤–∞—Ç–æ—Ä
/dd [—Ç–µ–∫—Å—Ç] ‚Äî —Ç–æ –∂–µ —Å–∞–º–æ–µ
/–¥ [—Ç–µ–∫—Å—Ç] ‚Äî —Ä—É—Å—Å–∫–∏–π –≤–∞—Ä–∏–∞–Ω—Ç
/–¥–¥ [—Ç–µ–∫—Å—Ç] ‚Äî —Ä—É—Å—Å–∫–∏–π –≤–∞—Ä–∏–∞–Ω—Ç

**–≠—Ñ—Ñ–µ–∫—Ç—ã:**
/inv [—Ç–µ–∫—Å—Ç] ‚Äî –∏–Ω–≤–µ—Ä—Å–∏—è —Ü–≤–µ—Ç–æ–≤
/vin [—Ç–µ–∫—Å—Ç] ‚Äî –≤–∏–Ω—Ç–∞–∂–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞

**–ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:**

1. –û—Ç–≤–µ—Ç—å –∫–æ–º–∞–Ω–¥–æ–π –Ω–∞ –ª—é–±–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
2. –ü–æ—Å–ª–µ –∫–æ–º–∞–Ω–¥—ã –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å —Ç–µ–∫—Å—Ç
3. –≠–º–æ–¥–∂–∏ –æ—Ç–æ–±—Ä–∞–∂–∞—é—Ç—Å—è —Ü–≤–µ—Ç–Ω—ã–º–∏! üî•üíØüòé

**–ü—Ä–∏–º–µ—Ä—ã:**

/d ‚Äî –æ–±—ã—á–Ω—ã–π –¥–µ–º–æ—Ç–∏–≤–∞—Ç–æ—Ä
/d –º–æ–π —Ç–µ–∫—Å—Ç üöÄ ‚Äî —Å —Ç–µ–∫—Å—Ç–æ–º –∏ —ç–º–æ–¥–∂–∏
/inv ‚Äî –∏–Ω–≤–µ—Ä—Å–∏—è
/vin –≤–∏–Ω—Ç–∞–∂ ‚Äî –≤–∏–Ω—Ç–∞–∂–Ω—ã–π —ç—Ñ—Ñ–µ–∫—Ç

**–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:**
- –¶–≤–µ—Ç–Ω—ã–µ —ç–º–æ–¥–∂–∏ —á–µ—Ä–µ–∑ Twemoji
- –≠—Ñ—Ñ–µ–∫—Ç—ã —Ç–æ–ª—å–∫–æ –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
- –í–∏–¥–µ–æ –¥–æ 30 —Å–µ–∫—É–Ω–¥
"""
    await message.answer(help_text)

async def get_random_fallback_image(message_id: int) -> str:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Ç—å –∫ —Ä–∞–Ω–¥–æ–º–Ω–æ–π –∑–∞–≥–ª—É—à–∫–µ: 123.png –∏–ª–∏ —Å—Ç–∏–∫–µ—Ä –∏–∑ –ø–∞–∫–∞"""
    try:
        # –°–ø–∏—Å–æ–∫ —Å—Ç–∏–∫–µ—Ä–ø–∞–∫–æ–≤
        sticker_packs = [
            "sp031fedcbc4e438a8984a76e28c81713d_by_stckrRobot",
            "sp70cc950ed11089c18703860f5419aa27_by_stckrRobot",
            "sp5e6aec1cfbfc458c3166a9bbb80e4bf2_by_stckrRobot",
            "sp40ba02f59a1bd3f647b89178bf001829_by_stckrRobot",
            "JowFaderMitch_by_fStikBot",
            "pa_PzVnv4JOlkayQOj8W8LQ_by_SigStick20Bot",
            "OninationSquadAnimStickers",
            "PerdunMorjopa_by_fStikBot",
            "vDfCbyQ_by_achestickbot",
            "woodcum",
            "ShooBeDoo",
            "pchellovod85434_by_sportsmem_bot",
            "pchellovod7569_by_sportsmem_bot",
            "l8da2e0PmqVX0fArOJ7A5vlCc_by_literalmebot",
            "vdyrky",
            "pchellovod78493_by_sportsmem_bot",
            "f_weyjrjak_896383854_by_fStikBot",
            "pchellovod84489_by_Kinopoisk_Memes_bot",
            "Hiroon_RafGrassetti",
            "with_love_for_680300712_by_msu_hub_bot",
            "with_love_for_1001414584186_by_msu_hub_bot",
            "dedobemebykot",
            "igorvikhorkov_by_fStikBot",
            "horsestikerisfiu_by_fStikBot",
            "with_love_for_1001615989157_by_msu_hub_bot",
            "peepee_poopoo",
            "Miss_evidence",
            "set_2900_by_makestick3_bot",
            "GamingYarAnimated",
            "Fortrach",
            "mihalpalich",
            "tapok2",
            "airplanshaha",
            "GospodJesus",
            "bttvAni",
            "Harry_Potter_stickers",
            "gifki",
            "skzkz",
            "Eto_golub_eeZee",
            "BoysClub",
            "anegen_2",
            "electroeditions",
            "NonameR",
            "tashkent_stickers",
            "KAZINO",
            "uktambek",
            "ChineseCubes",
            "BEPHO",
            "ButlerOstin",
            "Mosamapack",
            "Moral_condemnation",
            "als_ohuenny",
            "Stickers_ebat",
            "RESTORENATURALORDER",
            "blobbyyyy",
            "VitaminParty",
            "pollitrovaya",
            "LMTBZH_people",
            "sp760f8c50d2ff59b6231022bcb81e1e66_by_stckrRobot",
            "IgorIvanovich_by_fStikBot",
            "blyaskolko",
            "f_ws1afq2_1216979815_by_fStikBot",
            "modern2",
            "Rudiemoji",
            "AtiltDitalMasus_by_fStikBot",
            "kulhaker_salt",
            "peepee_poopoo",
            "ozero",
            "stkrchat",
            "putinsmoney",
            "daEntoOn",
            "PBaas",
            "best_ecosystem",
            "Yellowboi",
            "vsrpron",
            "set_2900_by_makestick3_bot",
            "ultrarjombav2",
        ]
        
        # –° –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é 2% –±–µ—Ä—ë–º 123.png, –∏–Ω–∞—á–µ —Å—Ç–∏–∫–µ—Ä
        if random.random() < 0.02 and os.path.exists(FALLBACK_AVATAR):
            output_file = f"temp_fallback_{message_id}.png"
            copy2(FALLBACK_AVATAR, output_file)
            logging.info("Using 123.png as fallback")
            return output_file
        
        # –í—ã–±–∏—Ä–∞–µ–º —Å–ª—É—á–∞–π–Ω—ã–π –ø–∞–∫ (–ë–ï–ó –ö–ï–®–ê)
        pack_name = random.choice(sticker_packs)
        logging.info(f"Getting random sticker from pack: {pack_name}")
        
        # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∏–∫–µ—Ä–ø–∞–∫
        sticker_set = await bot.get_sticker_set(pack_name)
        
        if not sticker_set.stickers:
            logging.warning("Sticker pack is empty, using 123.png")
            if os.path.exists(FALLBACK_AVATAR):
                output_file = f"temp_fallback_{message_id}.png"
                copy2(FALLBACK_AVATAR, output_file)
                return output_file
            return None
        
        # –ë–µ—Ä—ë–º –õ–Æ–ë–û–ô —Å—Ç–∏–∫–µ—Ä (–≤–∫–ª—é—á–∞—è –∞–Ω–∏–º–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∏ –≤–∏–¥–µ–æ)
        sticker = random.choice(sticker_set.stickers)
        logging.info(f"Selected sticker: animated={sticker.is_animated}, video={sticker.is_video}")
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ
        if sticker.is_animated:
            # TGS —Å—Ç–∏–∫–µ—Ä—ã - –ø–æ–∫–∞ –±–µ—Ä—ë–º –ø—Ä–µ–≤—å—é
            if sticker.thumbnail:
                output_file = f"temp_fallback_{message_id}.jpg"
                await bot.download(sticker.thumbnail, destination=output_file)
            else:
                # –ù–µ—Ç –ø—Ä–µ–≤—å—é - –±–µ—Ä—ë–º –¥—Ä—É–≥–æ–π
                return await get_random_fallback_image(message_id)
        elif sticker.is_video:
            output_file = f"temp_fallback_{message_id}.webm"
            await bot.download(sticker, destination=output_file)
        else:
            output_file = f"temp_fallback_{message_id}.webp"
            await bot.download(sticker, destination=output_file)
        
        logging.info(f"Downloaded sticker: {output_file}")
        return output_file
        
    except Exception as e:
        logging.error(f"Failed to get random fallback: {e}", exc_info=True)
        
        # Fallback –Ω–∞ 123.png
        if os.path.exists(FALLBACK_AVATAR):
            output_file = f"temp_fallback_{message_id}.png"
            copy2(FALLBACK_AVATAR, output_file)
            return output_file
        
        return None

# @dp.message(F.sticker)
# async def handle_sticker_direct(message: Message):
#     """–ü—Ä—è–º–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Ç–∏–∫–µ—Ä–æ–≤ –±–µ–∑ –∫–æ–º–∞–Ω–¥—ã"""
#     logging.info(f"Direct sticker received: is_animated={message.sticker.is_animated}")
    
#     status_msg = await message.reply("‚è≥ –î–µ–ª–∞–µ–º –¥–µ–º–æ—Ç–∏–≤–∞—Ç–æ—Ä...")
    
#     input_file = f"temp_in_{message.message_id}"
#     output_file = f"temp_out_{message.message_id}.jpg"
#     final_caption = "..."
    
#     try:
#         if message.sticker.is_animated:
#             logging.info("Processing TGS sticker")
#             input_file += ".tgs"
#             await bot.download(message.sticker, destination=input_file)
            
#             video_file = input_file.replace(".tgs", "_anim.mp4")
#             await status_msg.edit_text("‚è≥ –†–µ–Ω–¥–µ—Ä–∏–º –∞–Ω–∏–º–∞—Ü–∏—é...")
            
#             logging.info(f"Converting TGS: {input_file} -> {video_file}")
#             success = await run_in_thread(lambda: convert_tgs_to_mp4_simple(input_file, video_file))
            
#             if success:
#                 output_file = f"temp_out_{message.message_id}.mp4"
#                 if await run_in_thread(lambda: create_demotivator_video(video_file, final_caption, output_file)):
#                     await message.answer_animation(FSInputFile(output_file))
#                 else:
#                     await message.answer("–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏")
                
#                 if os.path.exists(video_file):
#                     os.remove(video_file)
#             else:
#                 # Fallback –Ω–∞ –ø—Ä–µ–≤—å—é
#                 if message.sticker.thumbnail:
#                     input_file = input_file.replace(".tgs", ".jpg")
#                     await bot.download(message.sticker.thumbnail, destination=input_file)
#                     success = await run_in_thread(lambda: create_demotivator_image(input_file, final_caption, output_file, is_avatar=True))
#                     if success:
#                         await message.answer_photo(FSInputFile(output_file))
        
#         elif message.sticker.is_video:
#             # –í–∏–¥–µ–æ-—Å—Ç–∏–∫–µ—Ä
#             input_file += ".webm"
#             await bot.download(message.sticker, destination=input_file)
#             output_file = f"temp_out_{message.message_id}.mp4"
            
#             if await run_in_thread(lambda: create_demotivator_video(input_file, final_caption, output_file)):
#                 await message.answer_animation(FSInputFile(output_file))
        
#         else:
#             # –û–±—ã—á–Ω—ã–π WEBP
#             input_file += ".webp"
#             await bot.download(message.sticker, destination=input_file)
#             success = await run_in_thread(lambda: create_demotivator_image(input_file, final_caption, output_file, is_avatar=True))
#             if success:
#                 await message.answer_photo(FSInputFile(output_file))
    
#     except Exception as e:
#         logging.error(f"Direct sticker error: {e}", exc_info=True)
#         await message.answer("–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏")
    
#     finally:
#         try:
#             await status_msg.delete()
#         except:
#             pass
        
#         # Cleanup
#         for f in os.listdir("."):
#             if f.startswith(f"temp_in_{message.message_id}") or \
#                f.startswith(f"temp_out_{message.message_id}"):
#                 try:
#                     os.remove(f)
#                 except:
#                     pass
                    
@dp.message(F.photo | F.document)
async def handle_media_with_caption(message: Message):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞—Ä—Ç–∏–Ω–æ–∫/–¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å –∫–æ–º–∞–Ω–¥–æ–π –≤ –ø–æ–¥–ø–∏—Å–∏"""
    caption = message.caption or ""
    
    cmd_prefixes = ("/d ", "/dd ", "/–¥ ", "/–¥–¥ ", "/inv ", "/vin ")
    cmd_list = ["/d", "/dd", "/–¥", "/–¥–¥", "/inv", "/vin"]
    
    is_cmd = caption.lower().startswith(tuple(cmd_prefixes)) or caption.lower() in cmd_list
    
    if not is_cmd:
        return
    
    # === –î–û–ë–ê–í–¨ –ü–†–û–í–ï–†–ö–£ –ù–ê–ì–†–£–ó–ö–ò ===
    can_process, process_count = check_server_load()
    if not can_process:
        logging.warning(f"Server overloaded ({process_count} processes), rejecting media from {message.from_user.id}")
        await send_overload_message(message, process_count)
        return
    # === –ö–û–ù–ï–¶ –ü–†–û–í–ï–†–ö–ò ===

        
    
    logging.info(f"Media with command caption: {caption[:50]}")
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —ç—Ñ—Ñ–µ–∫—Ç
    effect = None
    if caption.lower().startswith("/inv"):
        effect = "invert"
    elif caption.lower().startswith("/vin"):
        effect = "vintage"
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è –¥–µ–º–æ—Ç–∏–≤–∞—Ç–æ—Ä–∞
    parts = caption.split(maxsplit=1)
    final_caption = parts[1] if len(parts) > 1 else "..."
    
    status_msg = await message.reply("‚è≥ –î–µ–ª–∞–µ–º –¥–µ–º–æ—Ç–∏–≤–∞—Ç–æ—Ä...")
    
    input_file = f"temp_in_{message.message_id}.jpg"
    output_file = f"temp_out_{message.message_id}.jpg"
    
    try:
        # –°–∫–∞—á–∏–≤–∞–µ–º —Ñ–æ—Ç–æ –∏–ª–∏ –¥–æ–∫—É–º–µ–Ω—Ç
        if message.photo:
            await bot.download(message.photo[-1], destination=input_file)
        else:
            await bot.download(message.document, destination=input_file)
        
        logging.info(f"Processing media with caption: '{final_caption}'")
        
        # –°–æ–∑–¥–∞—ë–º –¥–µ–º–æ—Ç–∏–≤–∞—Ç–æ—Ä
        success = await run_in_thread(lambda: create_demotivator_image(
            input_file, final_caption, output_file, effect=effect
        ))
        
        if success:
            await message.answer_photo(FSInputFile(output_file))
        else:
            await message.answer("–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏")
    
    except Exception as e:
        logging.error(f"Media caption handler error: {e}", exc_info=True)
        await message.answer("–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞")
    
    finally:
        try:
            await status_msg.delete()
        except:
            pass
        
        # Cleanup
        for f in [input_file, output_file]:
            if os.path.exists(f):
                try:
                    os.remove(f)
                except:
                    pass


@dp.message(F.text)
async def handle_command(message: Message):
    txt = message.text.strip()
    cmd_prefixes = ("/d ", "/dd ", "/–¥ ", "/–¥–¥ ", "/inv ", "/vin ")
    cmd_list = ["/d", "/dd", "/–¥", "/–¥–¥", "/inv", "/vin"]
    
    is_cmd = txt.lower() in cmd_list or any(txt.lower().startswith(p) for p in cmd_prefixes)
    if not is_cmd:
        return

    # === –î–û–ë–ê–í–¨ –ü–†–û–í–ï–†–ö–£ –ù–ê–ì–†–£–ó–ö–ò ===
    can_process, process_count = check_server_load()
    if not can_process:
        logging.warning(f"Server overloaded ({process_count} processes), rejecting request from {message.from_user.id}")
        await send_overload_message(message, process_count)
        return
    # === –ö–û–ù–ï–¶ –ü–†–û–í–ï–†–ö–ò ===
    
    # === –ó–ê–ú–ï–ù–ò –≠–¢–£ –ü–†–û–í–ï–†–ö–£ ===
    if not message.reply_to_message:
        logging.info("Command without reply - using random sticker")
        
        parts = txt.split(maxsplit=1)
        
        # –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç –Ω–µ —É–∫–∞–∑–∞–Ω - –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º AI
        if len(parts) == 1:
            caption = generate_demotivator_text()
            logging.info(f"Using AI-generated caption: {caption}")
        else:
            caption = parts[1]
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —ç—Ñ—Ñ–µ–∫—Ç
        effect = None
        if txt.lower().startswith("/inv"):
            effect = "invert"
        elif txt.lower().startswith("/vin"):
            effect = "vintage"
        
        status_msg = await message.reply("‚è≥ –í—ã–±–∏—Ä–∞—é —Å—Ç–∏–∫–µ—Ä...")
        
        input_file = f"temp_in_{message.message_id}"
        output_file = f"temp_out_{message.message_id}.jpg"
        
        try:
            # –ü–æ–ª—É—á–∞–µ–º —Ä–∞–Ω–¥–æ–º–Ω—ã–π —Å—Ç–∏–∫–µ—Ä (–≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ —Å—Ç–∏–∫–µ—Ä, –Ω–µ 123.png)
            fallback_file = await get_random_fallback_image(message.message_id)
            
            if not fallback_file:
                await message.answer("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å—Ç–∏–∫–µ—Ä")
                await status_msg.delete()
                return
            
            logging.info(f"Using fallback file: {fallback_file}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∏–ø —Ñ–∞–π–ª–∞
            if fallback_file.endswith('.webm'):
                # –í–∏–¥–µ–æ-—Å—Ç–∏–∫–µ—Ä -> –≤–∏–¥–µ–æ –¥–µ–º–æ—Ç–∏–≤–∞—Ç–æ—Ä
                output_file = f"temp_out_{message.message_id}.mp4"
                success = await run_in_thread(lambda: create_demotivator_video(
                    fallback_file, caption, output_file
                ))
                if success:
                    await message.answer_animation(FSInputFile(output_file))
                else:
                    await message.answer("–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏")
            else:
                # –°—Ç–∞—Ç–∏—á–Ω—ã–π —Å—Ç–∏–∫–µ—Ä -> —Ñ–æ—Ç–æ –¥–µ–º–æ—Ç–∏–≤–∞—Ç–æ—Ä
                success = await run_in_thread(lambda: create_demotivator_image(
                    fallback_file, caption, output_file, is_avatar=True, effect=effect
                ))
                if success:
                    await message.answer_photo(FSInputFile(output_file))
                else:
                    await message.answer("–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏")
        
        except Exception as e:
            logging.error(f"Solo command error: {e}", exc_info=True)
            await message.answer("–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å—Ç–∏–∫–µ—Ä–∞")
        
        finally:
            try:
                await status_msg.delete()
            except:
                pass
            
            # Cleanup - —É–¥–∞–ª—è–µ–º –í–°–ï –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
            cleanup_patterns = [
                f"temp_fallback_{message.message_id}*",
                f"temp_in_{message.message_id}*",
                f"temp_out_{message.message_id}*",
            ]
            
            import glob
            for pattern in cleanup_patterns:
                for file_path in glob.glob(pattern):
                    try:
                        os.remove(file_path)
                        logging.debug(f"Cleaned up: {file_path}")
                    except Exception as e:
                        logging.debug(f"Failed to cleanup {file_path}: {e}")
        
        return  # –í—ã—Ö–æ–¥–∏–º –∏–∑ —Ñ—É–Ω–∫—Ü–∏–∏
    
    # –î–∞–ª—å—à–µ –∏–¥—ë—Ç –æ–±—ã—á–Ω–∞—è –ª–æ–≥–∏–∫–∞ —Å reply_to_message
    effect = None
    if txt.lower().startswith("/inv"):
        effect = "invert"
    elif txt.lower().startswith("/vin"):
        effect = "vintage"
    
    caption = ""
    parts = txt.split(maxsplit=1)
    if len(parts) > 1:
        caption = parts[1]
    
    replied = message.reply_to_message

    # === –î–û–ë–ê–í–¨ –≠–¢–ò –õ–û–ì–ò ===
    logging.info(f"Command handler: replied message type check")
    logging.info(f"  video={replied.video is not None}")
    logging.info(f"  animation={replied.animation is not None}")
    logging.info(f"  video_note={replied.video_note is not None}")
    logging.info(f"  sticker={replied.sticker is not None}")
    if replied.sticker:
        logging.info(f"  sticker.is_animated={replied.sticker.is_animated}")
        logging.info(f"  sticker.is_video={replied.sticker.is_video}")
    logging.info(f"  photo={replied.photo is not None}")
    logging.info(f"  document={replied.document is not None}")
    logging.info(f"  text={replied.text is not None}")

    # === –ö–û–ù–ï–¶ –õ–û–ì–û–í ===


    status_msg = await message.reply("‚è≥ –î–µ–ª–∞–µ–º...")

    input_file = f"temp_in_{message.message_id}"
    output_file = f"temp_out_{message.message_id}.jpg"
    text_img_file = f"temp_text_{message.message_id}.jpg"

    try:
        final_caption = caption if caption else "..."
        # === –í–ò–î–ï–û-–ö–†–£–ñ–ö–ò ===
        if replied.video_note:
            logging.info("Branch: video_note")
            input_file += ".mp4"
            output_file = f"temp_out_{message.message_id}.mp4"
            
            await bot.download(replied.video_note, destination=input_file)
            await status_msg.edit_text("‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫—Ä—É–∂–æ–∫...")
            
            success = await run_in_thread(lambda: create_demotivator_video(input_file, final_caption, output_file))
            
            if success:
                await message.answer_animation(FSInputFile(output_file))
            else:
                await message.answer("–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫—Ä—É–∂–∫–∞")
        
        # === –í–ò–î–ï–û ===
        elif replied.video or replied.animation:
            logging.info("Branch: video/animation")
            if effect:
                await message.answer("–≠—Ñ—Ñ–µ–∫—Ç—ã —Ä–∞–±–æ—Ç–∞—é—Ç —Ç–æ–ª—å–∫–æ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏")
                await status_msg.delete()
                return
                
            if replied.video:
                obj, ext = replied.video, ".mp4"
            elif replied.animation:
                obj, ext = replied.animation, ".mp4"
            else:
                obj, ext = replied.sticker, ".webm"

            input_file += ext
            output_file = f"temp_out_{message.message_id}.mp4"

            await bot.download(obj, destination=input_file)
            await status_msg.edit_text("‚è≥ –†–µ–Ω–¥–µ—Ä–∏–º –≤–∏–¥–µ–æ...")

            success = await run_in_thread(lambda: create_demotivator_video(input_file, final_caption, output_file))

            if success:
                await message.answer_animation(FSInputFile(output_file))
            else:
                await message.answer("–û—à–∏–±–∫–∞ –≤–∏–¥–µ–æ")

        # === –ö–ê–†–¢–ò–ù–ö–ò ===
        elif replied.photo or (replied.document and replied.document.mime_type and "image" in replied.document.mime_type):
            logging.info("Branch: photo/image_document")
            obj = replied.photo[-1] if replied.photo else replied.document

            input_file += ".jpg"
            await bot.download(obj, destination=input_file)
            
            success = await run_in_thread(lambda: create_demotivator_image(input_file, final_caption, output_file, effect=effect))

            if success:
                await message.answer_photo(FSInputFile(output_file))
            else:
                await message.answer("–û—à–∏–±–∫–∞ —Ñ–æ—Ç–æ")

        # === –°–¢–ò–ö–ï–†–´ ===
        elif replied.sticker:
            logging.info(f"Branch: sticker (is_video={replied.sticker.is_video})")
            
            # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ–∞–π–ª–µ
            file_info = await bot.get_file(replied.sticker.file_id)
            file_path = file_info.file_path
            logging.info(f"Sticker file_path: {file_path}")
            
            # TGS —Å—Ç–∏–∫–µ—Ä—ã –∏–º–µ—é—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ .tgs
            if file_path and file_path.endswith('.tgs'):
                logging.info("Processing TGS sticker (animated)")
                input_file += ".tgs"
                await bot.download(replied.sticker, destination=input_file)
                logging.info(f"TGS downloaded to {input_file}")
                
                video_file = input_file.replace(".tgs", "_anim.mp4")
                await status_msg.edit_text("‚è≥ –†–µ–Ω–¥–µ—Ä–∏–º –∞–Ω–∏–º–∞—Ü–∏—é...")
                
                logging.info(f"Converting TGS: {input_file} -> {video_file}")
                success = await run_in_thread(lambda: convert_tgs_to_mp4_simple(input_file, video_file))
                logging.info(f"TGS conversion result: {success}")
                
                if success:
                    output_file = f"temp_out_{message.message_id}.mp4"
                    if await run_in_thread(lambda: create_demotivator_video(video_file, final_caption, output_file)):
                        await message.answer_animation(FSInputFile(output_file))
                    else:
                        await message.answer("–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏")
                    
                    if os.path.exists(video_file):
                        os.remove(video_file)
                else:
                    # Fallback –Ω–∞ –ø—Ä–µ–≤—å—é
                    if replied.sticker.thumbnail:
                        input_file = input_file.replace(".tgs", ".jpg")
                        await bot.download(replied.sticker.thumbnail, destination=input_file)
                        success = await run_in_thread(lambda: create_demotivator_image(input_file, final_caption, output_file, is_avatar=True, effect=effect))
                        if success:
                            await message.answer_photo(FSInputFile(output_file))
            
            # –í–∏–¥–µ–æ-—Å—Ç–∏–∫–µ—Ä—ã (.webm)
            elif file_path and file_path.endswith('.webm'):
                logging.info("Processing WEBM video sticker")
                if effect:
                    await message.answer("–≠—Ñ—Ñ–µ–∫—Ç—ã —Ä–∞–±–æ—Ç–∞—é—Ç —Ç–æ–ª—å–∫–æ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏")
                    await status_msg.delete()
                    return
                
                input_file += ".webm"
                output_file = f"temp_out_{message.message_id}.mp4"
                await bot.download(replied.sticker, destination=input_file)
                
                logging.info("Creating video demotivator from WEBM")
                success = await run_in_thread(lambda: create_demotivator_video(input_file, final_caption, output_file))
                logging.info(f"WEBM demotivator result: {success}, file exists: {os.path.exists(output_file)}")
                
                if success:
                    await message.answer_animation(FSInputFile(output_file))
                else:
                    await message.answer("–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∏–¥–µ–æ —Å—Ç–∏–∫–µ—Ä–∞")
            
            # –û–±—ã—á–Ω—ã–µ WEBP —Å—Ç–∏–∫–µ—Ä—ã
            else:
                logging.info("Processing static WEBP sticker")
                input_file += ".webp"
                await bot.download(replied.sticker, destination=input_file)
                success = await run_in_thread(lambda: create_demotivator_image(input_file, final_caption, output_file, is_avatar=True, effect=effect))
                if success:
                    await message.answer_photo(FSInputFile(output_file))

        # === –¢–ï–ö–°–¢ ===
        elif replied.text:
            text_content = replied.text.strip()
            user_id = replied.from_user.id
            avatar_available = False
            
            try:
                photos = await bot.get_user_profile_photos(user_id, limit=1)
                
                if photos.total_count > 0:
                    input_file += ".jpg"
                    await bot.download(photos.photos[0][-1], destination=input_file)
                    avatar_available = True
                else:
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–∞–Ω–¥–æ–º–Ω—É—é –∑–∞–≥–ª—É—à–∫—É –≤–º–µ—Å—Ç–æ 123.png
                    fallback_file = await get_random_fallback_image(message.message_id)
                    if fallback_file:
                        input_file = fallback_file
                        avatar_available = True
            except:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–∞–Ω–¥–æ–º–Ω—É—é –∑–∞–≥–ª—É—à–∫—É
                fallback_file = await get_random_fallback_image(message.message_id)
                if fallback_file:
                    input_file = fallback_file
                    avatar_available = True
            
            if avatar_available:
                text_for_demot = caption if caption else text_content
                success = await run_in_thread(lambda: create_demotivator_image(input_file, text_for_demot, output_file, is_avatar=True, effect=effect))
                if success:
                    await message.answer_photo(FSInputFile(output_file))
            else:
                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏–∑ —Ç–µ–∫—Å—Ç–∞
                text_for_caption = caption if caption else "..."
                if await run_in_thread(lambda: generate_text_image(text_content, text_img_file)):
                    if await run_in_thread(lambda: create_demotivator_image(text_img_file, text_for_caption, output_file, effect=effect)):
                        await message.answer_photo(FSInputFile(output_file))

        # === FALLBACK ===
        else:
            fallback_text = caption if caption else "Unknown"
            if await run_in_thread(lambda: generate_text_image(fallback_text, text_img_file)):
                if await run_in_thread(lambda: create_demotivator_image(text_img_file, fallback_text, output_file, effect=effect)):
                    await message.answer_photo(FSInputFile(output_file))

    except Exception as e:
        logging.error(f"Error: {e}", exc_info=True)
        await message.answer("–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏")
    finally:
        try:
            await status_msg.delete()
        except:
            pass
        
        # Cleanup
        for f in os.listdir("."):
            if f.startswith(f"temp_in_{message.message_id}") or \
               f.startswith(f"temp_out_{message.message_id}") or \
               f.startswith(f"temp_text_{message.message_id}") or \
               f.startswith(f"temp_fallback_{message.message_id}"):
                try:
                    os.remove(f)
                except:
                    pass

async def main():
    await bot.delete_webhook(drop_pending_updates=True)
    logging.info("Bot with emoji support started!")
    cleanup_old_temp_files()
    await dp.start_polling(bot)

if __name__ == "__main__":
    asyncio.run(main())
